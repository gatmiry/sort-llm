{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ba2904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(257, 32)\n",
       "    (wpe): Embedding(65, 32)\n",
       "    (h): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (c_attn): CasualSelfAttention(\n",
       "          (c_attn): Linear(in_features=32, out_features=96, bias=True)\n",
       "          (c_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (c_fc): MLP(\n",
       "          (fc_1): Linear(in_features=32, out_features=96, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (fc_2): Linear(in_features=96, out_features=32, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_tbyt_3 import GPT, GPTConfig\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def remap_state_dict_keys(state_dict):\n",
    "    \"\"\"Remap keys from notebook model naming to model_tbyt_3.py naming.\"\"\"\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        new_key = k.replace('.attn.', '.c_attn.').replace('.mlp.', '.c_fc.')\n",
    "        new_state_dict[new_key] = v\n",
    "    return new_state_dict\n",
    "\n",
    "itr_num = 60000\n",
    "block_size = 16\n",
    "vocab_size = 256\n",
    "device = 'cpu'\n",
    "config = GPTConfig(block_size=block_size, vocab_size=vocab_size)\n",
    "model = GPT(config)\n",
    "model_state_dict = torch.load(os.path.join(os.getcwd(), f'saved_models/Final_N256_K16_L2_H1_E32_r8over1_npos1_mlp1_dup0_testK16_iters60000.pt'), map_location=device)['model']\n",
    "model_state_dict = remap_state_dict_keys(model_state_dict)\n",
    "\n",
    "# Handle wpe size mismatch manually (checkpoint has 33, model has 65)\n",
    "wpe_key = 'transformer.wpe.weight'\n",
    "if wpe_key in model_state_dict:\n",
    "    checkpoint_wpe = model_state_dict.pop(wpe_key)  # Remove from state_dict\n",
    "    with torch.no_grad():\n",
    "        model.transformer.wpe.weight[:checkpoint_wpe.size(0), :] = checkpoint_wpe\n",
    "\n",
    "model.load_state_dict(model_state_dict, strict=False)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4600074",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "#test_1_seq = torch.cat((torch.arange(110, 30, -5) , torch.arange(127, 111, -1)), dim=0) \n",
    "#print(test_1_seq)\n",
    "def get_batch(changing_num=-1, changing_index=-1, initial_sequence=None, batch_size=batch_size):\n",
    "   def cat_sorted_tensor(x):\n",
    "      if initial_sequence is not None:\n",
    "         x = initial_sequence\n",
    "      else:\n",
    "         x = x\n",
    "         #x, _ = torch.sort(x, descending=True)\n",
    "      if changing_num != -1:\n",
    "         if changing_index == -1:\n",
    "            x[0] = changing_num\n",
    "         else:\n",
    "            x[changing_index] = changing_num\n",
    "      #x = torch.cat((torch.tensor([100]).repeat(16), torch.tensor([1]).repeat(16)))\n",
    "      #x = torch.tensor([100,100,100,100,1,1,1,1])\n",
    "      vals, _ = torch.sort(x)\n",
    "      #vals2, _ = torch.sort(x, descending=True)\n",
    "      #print('vals are ', vals)\n",
    "      return torch.cat((x, torch.tensor([vocab_size]), vals), dim=0)\n",
    "   #x = torch.stack([cat_sorted_tensor(torch.randperm(vocab_size)[:block_size]) for _ in range(batch_size)])\n",
    "   x = torch.stack([cat_sorted_tensor(torch.randperm(vocab_size)[:block_size]) for _ in range(batch_size)])\n",
    "   return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601569bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx dim is  torch.Size([1, 33])\n",
      "layer_n is  0\n",
      "layer_n is  1\n",
      "loss is  5.624738693237305\n",
      "idx is: tensor([[132,  95, 187, 143, 204,  64, 173, 172,  83,  87, 190,  26, 149,  32,\n",
      "          67,  19, 256,  19,  26,  32,  64,  67,  83,  87,  95, 132, 143, 149,\n",
      "         172, 173, 187, 190, 204]])\n"
     ]
    }
   ],
   "source": [
    "idx = get_batch()\n",
    "print('idx dim is ', idx.shape)\n",
    "logits, loss = model(idx)\n",
    "print('loss is ', loss.item())\n",
    "print(f'idx is: {idx}')\n",
    "print('model output is ', torch.argmax(logits, dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
